{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <h1 style=\"font-size:30px;\">PROJEKTNI ZADATAK</h1>\n",
    "    <p style=\"font-size:25px;\">--Prvi dio--</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">U ovom dijelu projektnog zadatka kreirana je i istrenirana neuronska mreža nad RCV1 skupom podataka. \n",
    "Za rad sa neuronskom mrežom koristila sam biblioteku TensorFlow. Ukoliko se koristi GoogleColab ova biblioteka je automatski instalirana, u slučaju da nije instalirana na računaru to je moguće uraditi iz komandne linije naredbom:</p>\n",
    "\n",
    "<div style=\"text-align:center; color:green; font-size:16px;\">\n",
    "    pip install tensorflow\n",
    "</div>\n",
    "\n",
    "<p style=\"font-size:16px;\">Za izbor ove biblioteke sam se odlučila zato što je pogodnija za početnike i nudi neposrednu podršku za sparse matrice, dok je u PyTorch-u rad sa sparse matricama nešto manje razvijen. S obzirom da su podaci dati u ovom formatu izabrala sam TensorFlow.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">Prvo što radimo je importovanje traženog skupa podataka i dijelimo ga tako da radimo sa 50% uzoraka što je u našem konkretnom slučaju dozvoljeno jer se radi o veoma velikom dataset-u, a inače za bolje performanse preporučuje se naravno treniranje cijelog skupa.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1 #importovanje trazenog skupa podataka\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "\n",
    "#preuzimanje RCV1 podataka\n",
    "rcv1 = fetch_rcv1()\n",
    "\n",
    "#uzimamo podatke i ciljeve iz skupa podataka\n",
    "X = rcv1.data\n",
    "y = rcv1.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postavljanje random seed za reprodukciju rezultata\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#izracunavanje broja uzoraka koji cini 50% dataset-a\n",
    "n_samples = X.shape[0]\n",
    "n_subset = n_samples // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nasumicno biranje 50% uzoraka\n",
    "indices = np.random.choice(n_samples, n_subset, replace=False)\n",
    "X_subset = X[indices]\n",
    "y_subset = y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\">U narednih nekoliko ćelija služi analiziramo podatake da bi znali sa čime radimo i na ispravan način osmilili arhitekturu neuronske mreže koju ćemo koristiti.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">Ulazni podaci (X_subset) imaju oblik sparse matrice, gde je svaka instanca reprezentovana sa odredjenim brojem karakteristika to jest kolona. Upravo taj broj kolona u matrici X_subset predstavlja broj karakteristika za svaku instancu, što direktno odredjuje broj ulaznih neurona. Dakle, svaki neuron u ulaznom sloju mreže odgovara jednoj karakteristici u podacima i zato zaključujemo da su nam potrebna 47236 neurona u ulaznom sloju.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj ulaznih neurona: 47236\n"
     ]
    }
   ],
   "source": [
    "num_input_neurons = X_subset.shape[1]\n",
    "print(f\"Broj ulaznih neurona: {num_input_neurons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">Izlazni podaci (y_subset) su takođe u obliku sparse matrice, gde broj kolona predstavlja broj klasa u slučaju klasifikacije. Broj izlaznih neurona određuje se prema broju različitih izlaznih vrednosti koje mreža treba da predvidi. U slučaju klasifikacije sa više klasa, broj izlaznih neurona je jednak broju klasa, te zaključujemo da će u našem slučaju broj izlaznih neurona biti 103.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj izlaznih neurona 103\n"
     ]
    }
   ],
   "source": [
    "num_output_neurons = y_subset.shape[1]\n",
    "print(f\"Broj izlaznih neurona {num_output_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nazivi klasa:\n",
      "['C11' 'C12' 'C13' 'C14' 'C15' 'C151' 'C1511' 'C152' 'C16' 'C17' 'C171'\n",
      " 'C172' 'C173' 'C174' 'C18' 'C181' 'C182' 'C183' 'C21' 'C22' 'C23' 'C24'\n",
      " 'C31' 'C311' 'C312' 'C313' 'C32' 'C33' 'C331' 'C34' 'C41' 'C411' 'C42'\n",
      " 'CCAT' 'E11' 'E12' 'E121' 'E13' 'E131' 'E132' 'E14' 'E141' 'E142' 'E143'\n",
      " 'E21' 'E211' 'E212' 'E31' 'E311' 'E312' 'E313' 'E41' 'E411' 'E51' 'E511'\n",
      " 'E512' 'E513' 'E61' 'E71' 'ECAT' 'G15' 'G151' 'G152' 'G153' 'G154' 'G155'\n",
      " 'G156' 'G157' 'G158' 'G159' 'GCAT' 'GCRIM' 'GDEF' 'GDIP' 'GDIS' 'GENT'\n",
      " 'GENV' 'GFAS' 'GHEA' 'GJOB' 'GMIL' 'GOBIT' 'GODD' 'GPOL' 'GPRO' 'GREL'\n",
      " 'GSCI' 'GSPO' 'GTOUR' 'GVIO' 'GVOTE' 'GWEA' 'GWELF' 'M11' 'M12' 'M13'\n",
      " 'M131' 'M132' 'M14' 'M141' 'M142' 'M143' 'MCAT']\n"
     ]
    }
   ],
   "source": [
    "#nazivi klasa predstavljaju skracenice u odnosu na tematiku clanka\n",
    "print(f\"Nazivi klasa:\")\n",
    "print(rcv1.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">Trening i test skup sam podijelila tako da 20% podataka bude u testnom skupu, a preostalih 80% u trening skupu. Uobičajena je praksa da testni skup bude izmedju 20% i 30% jer je tako omogućeno sasvim dovoljno podataka za testiranje modela, dok većina ostaje za obuku što je i ključno za učenje našeg modela.</p>\n",
    "\n",
    "<p style=\"font-size:16px;\">Shuffle služi za miješanje podataka kako bi se osiguralo da oba skupa budu reprezentativni i da ne postoji pristrasnost u redosledu podataka, dok postavljenjem random_state omogućavamo da svaki put kada se kod pokrene dobijemo isti rezultat, pri tome ne mora biti 42 može i bilo koji drugi broj.</p>\n",
    "\n",
    "<p style=\"font-size:16px;\">Na kraju za validacioni skup odabrala sam da se koristi pola od testnog skupa, što je 10% od ukupnih podataka. Time je dovoljno podataka (10%) izdvojeno za validaciju modela tokom treniranja, čime se pomaže u odabiru hiperparametara i izbegavanju overfittinga, kao i konačnih 10% podataka bude za završnu evaluaciju performansi modela na potpuno novim i neviđenim podacima.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podjela 50% uzoraka na trening i test skupove\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2,shuffle=True, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukupan broj uzoraka u dataset-u: 804414\n",
      "Broj uzoraka u podskupu (50%): 402207\n",
      "Broj uzoraka u trening skupu: 321765\n",
      "Broj uzoraka u test skupu: 40221\n"
     ]
    }
   ],
   "source": [
    "#samo trenutno za provjeru\n",
    "print(f'Ukupan broj uzoraka u dataset-u: {n_samples}')\n",
    "print(f'Broj uzoraka u podskupu (50%): {n_subset}')\n",
    "print(f'Broj uzoraka u trening skupu: {X_train.shape[0]}')\n",
    "print(f'Broj uzoraka u test skupu: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train: 47236\n",
      " X_test: 47236\n"
     ]
    }
   ],
   "source": [
    "n = X_train.shape[1]\n",
    "print(f\" X_train: {n}\")\n",
    "m = X_test.shape[1]\n",
    "print(f\" X_test: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y_train: 103\n",
      " y_train: 103\n"
     ]
    }
   ],
   "source": [
    "n = y_train.shape[1]\n",
    "print(f\" y_train: {n}\")\n",
    "m = y_train.shape[1]\n",
    "print(f\" y_train: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenzije:\n",
      "X_train: (321765, 47236)\n",
      "X_val: (40221, 47236)\n",
      "X_test: (40221, 47236)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimenzije:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenzije:\n",
      "y_train: (321765, 103)\n",
      "y_val: (40221, 103)\n",
      "y_test: (40221, 103)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimenzije:\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_val: {y_val.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postoji nekoliko razloga za narednu konverziju:\n",
    " - modeli za klasifikaciju obično očekuju oznake u obliku kategorijskih brojeva umesto one-hot kodovanih vektora\n",
    " - funkcija gubitka koju koristim očekuje oznake u obliku kategorija\n",
    "\n",
    "Tako da ovim korakom vršim pripremu oznaka za dalje treniranje i evaluaciju modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretvaranje sparse matrica u dense format, a zatim iz one-hot vektora u njihove odgovarajuce kategorije\n",
    "y_train = y_train.toarray().argmax(axis=1)\n",
    "y_val = y_val.toarray().argmax(axis=1)\n",
    "y_test = y_test.toarray().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Arhitektura neuronske mreže sačinjena je od **ulaznog**, **izlaznog** i **tri skrivena sloja**. Ranije je pojašnjen razlog za izbor broja ulaznih i izlaznih neurona, a što se tiče skrivenih slojeva u prvoj sloju je veći broj neurona što omogućava mreži da uči složenije obrasce iz podataka, taj broj kasnije sa slojevima smanjujemo radi dodatnog filtriranja informacija.\n",
    "\n",
    " - Koristim keras koji je API visokog nivoa za duboko učenje koji omogućava jednostavno kreiranje i treniranje neuronskih mreža. **Sequental** klasa služi za definisanje modela tako što pomoću nje doslovno slažemo slojeve jedan po jedan.\n",
    "\n",
    " - Kao aktivaciona funkcija izabrana je **ReLu** jer pomaže u dodavanju nelinearnosti, što je važno za učenje složenih funkcija.\n",
    "\n",
    " - U izlaznom sloju aktivaciona funkcija je **Softmax** jer se radi o višeklasnoj klasifikaciji pa je korisno što omogućava modelu da predvidja vjerovatnoće pripadnosti za svaku klasu.\n",
    "\n",
    " - Takodje korišćen je i **Dropout**. To je tehnika regularizacije koja pomaže u sprečavanju overfitting-a tako što nasumično isključuje odredjeni procenat neurona tokom treninga. Stopa od 0.5 se često koristi radi balansa izmedju regularizacije i gubitka informacija. Što zapravo znači da će 50% neurona biti isključeno u datom sloju tokom svake iteracije treniranja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#definisanje arhitekture neuronske mreze\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1], )),\n",
    "    layers.Dense(2048, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(103, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom dijelu koda definišemo ključne aspekte načina na koji će model biti treniran.\n",
    "\n",
    "- Optimizator je algoritam koji model koristi za ažuriranje težina tokom treniranja, tako da se minimizuje funkcija gubitka. **Adam optimizator** je odabran jer često postiže bolje rezultate u kraćem vremenskom roku i nisu potrebna neka naročita podešavanja stope učenja, to jest jednostavniji je za rad. On aptomatski prilagodjava stopu učenja za svaku težinu u modelu na osnovu trenutnih i prošlih gradijenata.\n",
    "\n",
    "- Funkcija greške **SparseCategoricalCrossentropy** se koristi za klasifikaciju sa integer kodovanim oznakama, umjesto one-hot kodovanja(zato ona prethodna konverzija), ovaj način sam izabrala prvenstveno jer je efikasniji u pogledu memorije, jer je broj klasa i podataka obiman. Funkcija gubitka inače služi da mjeri koliko su predikcije modela tačne u odnosu na stvarne vrijednosti, npr. ako model ne daje visoku vjerovatnoću stvarnoj klasi biće povećana funkcija gubitka.\n",
    "\n",
    "- **Accuracy** metrika je standardna za klasifikaciju i omogućava nam da pratimo performanse modela tokom obuke.\n",
    "\n",
    "- **ModelCheckpoint** omogućava povratak na najbolje performanse modela koje odredjuje na osnovu tačnosti validacionog skupa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#optimizator, funkcija greske i metrike\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#da sacuvamo  najbolji model\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">96,741,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,839</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m96,741,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)            │        \u001b[38;5;34m52,839\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,417,191</span> (379.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,417,191\u001b[0m (379.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,417,191</span> (379.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,417,191\u001b[0m (379.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#radi provjere da li je neuronska mreza kreirana\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trening traje 5 epoha prvenstveno zbog resurnih ograničenja, a manji broj epoha je generalno bolji ako duže obučavanje vodi do overfitting-a tada bi dodatno korstila i early stopping najvjerovatnije\n",
    "\n",
    "- Veličina batch-a je 64 (model ažurira svoje težine nakon što prodje kroz 64 primjera iz X_train odjednom) što je neka standardna vrijednost koja se uzima koja omogućava balans izmedju brze obuke i stabilnijih gradijenata\n",
    "\n",
    "- validation_data koristimo za provjeru performansi modela \n",
    "\n",
    "- Klasifikacioni izveštaj daje sveobuhvatan pregled performansi modela za svaku klasu, što je korisno za analizu kako se model ponaša prema različitim klasama.\n",
    "\n",
    "- callbacks osigurava da se najbolji model sacuva tokom treniranja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.7414 - loss: 0.9630\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83330, saving model to best_model.keras\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2943s\u001b[0m 585ms/step - accuracy: 0.7414 - loss: 0.9629 - val_accuracy: 0.8333 - val_loss: 0.5611\n",
      "Epoch 2/5\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.8672 - loss: 0.4562\n",
      "Epoch 2: val_accuracy improved from 0.83330 to 0.83576, saving model to best_model.keras\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2949s\u001b[0m 587ms/step - accuracy: 0.8672 - loss: 0.4562 - val_accuracy: 0.8358 - val_loss: 0.5511\n",
      "Epoch 3/5\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step - accuracy: 0.9024 - loss: 0.3309\n",
      "Epoch 3: val_accuracy did not improve from 0.83576\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2874s\u001b[0m 572ms/step - accuracy: 0.9024 - loss: 0.3309 - val_accuracy: 0.8349 - val_loss: 0.5990\n",
      "Epoch 4/5\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.9285 - loss: 0.2459\n",
      "Epoch 4: val_accuracy did not improve from 0.83576\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2867s\u001b[0m 570ms/step - accuracy: 0.9285 - loss: 0.2459 - val_accuracy: 0.8325 - val_loss: 0.7127\n",
      "Epoch 5/5\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step - accuracy: 0.9418 - loss: 0.2011\n",
      "Epoch 5: val_accuracy did not improve from 0.83576\n",
      "\u001b[1m5028/5028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2879s\u001b[0m 573ms/step - accuracy: 0.9418 - loss: 0.2011 - val_accuracy: 0.8302 - val_loss: 0.7844\n",
      "\u001b[1m1257/1257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.8403 - loss: 0.5425\n",
      "Test Accuracy: 0.8402824401855469\n",
      "\u001b[1m1257/1257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step\n",
      "Test Precision: 0.8376823230409104\n",
      "Test Recall: 0.8402824395216429\n",
      "Test F1 Score: 0.8374185600464313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.51      0.53      1228\n",
      "           1       0.76      0.78      0.77       624\n",
      "           2       0.61      0.57      0.59      1673\n",
      "           3       0.63      0.74      0.68       348\n",
      "           4       0.92      0.94      0.93      7217\n",
      "           8       0.53      0.59      0.56        54\n",
      "           9       0.81      0.79      0.80      1600\n",
      "          14       0.75      0.81      0.78      1727\n",
      "          18       0.71      0.55      0.62       938\n",
      "          19       0.56      0.49      0.52       199\n",
      "          20       0.67      0.50      0.57        70\n",
      "          21       0.55      0.54      0.55       757\n",
      "          22       0.76      0.62      0.68      1127\n",
      "          26       0.60      0.55      0.57        44\n",
      "          27       0.63      0.67      0.65       426\n",
      "          29       1.00      0.00      0.00         9\n",
      "          30       0.86      0.88      0.87       457\n",
      "          32       0.67      0.71      0.69       410\n",
      "          33       0.50      0.25      0.34        91\n",
      "          34       0.71      0.60      0.65       368\n",
      "          35       0.65      0.70      0.67      1059\n",
      "          37       0.85      0.84      0.85       232\n",
      "          40       0.71      0.78      0.74        58\n",
      "          44       0.85      0.83      0.84      1597\n",
      "          47       0.74      0.70      0.72        74\n",
      "          51       0.76      0.63      0.69       183\n",
      "          53       0.68      0.74      0.71       685\n",
      "          57       0.75      0.60      0.67        10\n",
      "          58       0.94      1.00      0.97       247\n",
      "          59       1.00      0.00      0.00        14\n",
      "          60       0.84      0.51      0.64       245\n",
      "          70       0.94      0.96      0.95      8062\n",
      "          93       0.93      0.95      0.94      2081\n",
      "          94       0.81      0.92      0.87      1109\n",
      "          95       0.92      0.89      0.91      1895\n",
      "          98       0.94      0.96      0.95      3298\n",
      "         102       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.84     40221\n",
      "   macro avg       0.76      0.66      0.67     40221\n",
      "weighted avg       0.84      0.84      0.84     40221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "#treniranje\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint])\n",
    "\n",
    "#ucitamo informacije koje smo sacuvali o najboljem modelu\n",
    "best_model = tf.keras.models.load_model('best_model.keras')\n",
    "\n",
    "#za taj model izvrsimo evaluaciju performansi\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "#predikcije na testnom skupu\n",
    "y_pred = best_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "#izracunamo metrike\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Test Precision: {precision}\")\n",
    "print(f\"Test Recall: {recall}\")\n",
    "print(f\"Test F1 Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <p style=\"font-size:25px;\">--Drugi dio--</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U drugom dijelu projektnog zadatka trebalo je da istreniramo LightGBM nad istim skupom podataka samo u ovom slučaju koristiti cijeli dataset, a ne samo 50%, pa sam ga zato opet učitala i podijelila podatke. Mada idealno bi bilo da je korišćen isti raspored podataka za treniranje i neuronske mreže i LightGBM-a jer je cilj bio uporediti performanse zbog restartovanja kernela to nije bilo moguće, pa će i ovi rezultati poslužiti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;\">Da bismo koristili Optunu za optimizaciju hiperparametara i LightGBM za treniranje modela potrebno je u komandnoj liniji pokrenuti sledeću naredbu. Takodje ako nije instalirana unaprijed i biblioteka sckit-learn i nju instaliramo.</p>\n",
    "\n",
    "<div style=\"text-align:center; color:green; font-size:16px;\">\n",
    "    pip install optuna lightgbm scikit-learn\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importovanje potrebnih biblioteka\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import optuna\n",
    "from scipy.sparse import csr_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Učitavanje RCV1 dataset-a\n",
    "rcv1 = fetch_rcv1()\n",
    "X = rcv1.data  # Sparse matrica (CSR format)\n",
    "y = rcv1.target  # Sparse matrica (multi-label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:22px;\">Pojašnjenje konverzija i načina klasifikacije</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orginalna ciljana promjenljiva y u RCV1 dataset-u je u multi-label formatu, gdje jedan uzorak može pripadati više klasa istovremeno. Medjutim, u ovom projektu prije svega zbog jednostavnosti fokusiramo se na problem višeklasifikacije tj. multi-class problem, gdje svaki uzorak treba da pripada samo jednoj klasi. Naravno važno je napomenuti da sa ovim pristupom gubimo neke informacije, što nije idealno, ali je neizbježno zbog načina na koji multi-class funkcioniše što ću pojasniti kasnije."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvo pretvaramo y u dense format da bismo mogli pronaći najvažnije oznake (labels). Svaki red predstavlja jedan uzorak, a svaka kolona jednu oznaku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretvaranje y iz sparse u dense format\n",
    "y_dense = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj uzoraka u svakoj klasi: [ 24325  11944  37410   7410 151785  81890  23211  73092   1920  42155\n",
      "  18313  11487   2636   5871  52817  43374   4671   7406  25403   6119\n",
      "   2625  32153  40509   4299   6648   1115   2084  15332   1210   4835\n",
      "  11355  10272  11878 381327   8568  27100   2182   6603   5659    939\n",
      "   2177    376    200   1206  43130  15768  27405   2415   1701     52\n",
      "    111  17035   2136  21280   2933  12634   2290    391   5268 119920\n",
      "  20672   3307   2107   2360   8404   2124    260   2036   4300     40\n",
      " 239267  32219   8842  37739   8657   3801   6261    313   6030  17241\n",
      "      5    844   2802  56878   5498   2849   2410  35317    680  32615\n",
      "  11532   3878   1869  48696  26036  53634  28185  26752  85440  47708\n",
      "  12130  21957 204820]\n",
      "Broj klasa sa uzorcima: 103\n"
     ]
    }
   ],
   "source": [
    "# Provjera broja uzoraka u svakoj klasi u originalnom multi-label skupu\n",
    "class_counts = np.sum(y_dense, axis=0)\n",
    "print(f\"Broj uzoraka u svakoj klasi: {class_counts}\")\n",
    "print(f\"Broj klasa sa uzorcima: {np.sum(class_counts > 0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U multi-label okruženju, jedan uzorak može imati više oznaka, ali za problem višeklasifikacije, svaki uzorak mora pripadati samo jednoj klasi. Funkcija np.argmax se koristi za izbor oznake sa najvećom vrednošću (ili značajem) za svaki uzorak. Ovo efikasno smanjuje problem sa više oznaka na problem sa jednom oznakom (multi-class) tako što se bira najistaknutija oznaka.\n",
    "- np.argmax je funkcija koja vraća indeks najveće vrijednosti duž određene ose (axis) u nizu\n",
    "- axis odredjuje duž koje ose treba da se izvrši operacija, u ovom slučaju axis=1 znači da se operacija izvršava duž redova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretvaranje multi-label u multi-class (biramo najvažniju labelu)\n",
    "y_multi_class = np.argmax(y_dense, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj klasa u originalnom y: 37\n"
     ]
    }
   ],
   "source": [
    "# Provjera broja klasa prije i poslije konverzije\n",
    "num_classes_original = np.unique(y_multi_class).shape[0]\n",
    "print(f\"Broj klasa u originalnom y: {num_classes_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podjela na train, val i test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_multi_class, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenzije y_train: (563089,)\n",
      "Dimenzije y_val: (120662,)\n",
      "Dimenzije y_test: (120663,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimenzije y_train:\", y_train.shape)\n",
    "print(\"Dimenzije y_val:\", y_val.shape)\n",
    "print(\"Dimenzije y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**param{...}** - u ovom dijelu se definišu hiperparametri modela koje Optuna treba da optimizuje. Svaki parametar ima odredjeni opseg ili skup mogućih vrijednosti iz kojeg Optuna nasumično bira i testira različite kombinacije.\n",
    "\n",
    "- **objective** definiše da se model trenira za multi-class klasifikaciju\n",
    "- **multi_logloss** mjeri koliko su predikcije modela loše\n",
    "\n",
    "Objašnjenje izbora opsega hiperparametara:\n",
    "- **learning_rate** odredjuje koliko će model korigovati svoje greške u svakom iterativnnom koraku; manja vrijednost znači sporije i stabilnije učenje, a veća može ubrzati učenje, ali postoji rizik da model preskoči optimalno rješenje(grafik sa vježbi)\n",
    "- **num_leaves** definiše maksimalan broj listova u svakom stablu; više listova omogućava modelu da napravi složenije odluke, ali može dovesti do overfitting-a\n",
    "- **feature_fraction** kontroliše dio karakteristika koje će se koristiti u svakoj boosting iteraciji; vrijednosti bliže 1.0 znače da će se skoro sve karakteristike koristiti, ako izaberemo manje sprječavamo mogućnost overfitting-a\n",
    "- **bagging_fraq** definiše koliko često će se bagging koristiti u iteracijama\n",
    "- **min_child_samples** definiše minimalan broj uzoraka koji je potreban da bi se formirao list u stablu; veća vrijednost manja šansa za overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biramo opsege koji su dovoljno široki da bi model mogao da testira različite strategije učenja sa različitim karakteristikama, a da opet ne bi došlo do overfitting-a i naravno obraćamo pažnju da ne pretjeramo sa opsegom jer bi to moglo dosta vremenski da traje npr. za veoma mali lr učenje može dosta da se oduži."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisanje funkcije cilja za Optuna\n",
    "def objective(trial):\n",
    "    start_time = time.time() # zapocnemo mjerenje za svaki trial\n",
    "    print(\"Pokretanje novog triala ...\")\n",
    "    param = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"num_class\": num_classes_original,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        #\"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),    \n",
    "    }\n",
    "    \n",
    "    # Treniranje modela\n",
    "    print(f\"Treniranje modela sa parametrima: {param}\")\n",
    "    model = lgb.LGBMClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Predvidjanje i evaluacija\n",
    "    print(\"Predviđanje na validacionom skupu...\")\n",
    "    y_pred = model.predict(X_val)\n",
    "    precision = precision_score(y_val, y_pred, average='weighted')  # Preciznost za multi-class problem\n",
    "\n",
    "    # Mjerenje i ispis vremena izvršavanja\n",
    "    end_time = time.time()\n",
    "    trial_time = end_time - start_time\n",
    "    print(f\"Trial {trial.number} završen za {trial_time:.2f} sekundi s preciznošću: {precision:.4f}\")\n",
    "    \n",
    "    # Vraca se preciznost modela, koja ce se koristiti za procjenu kvaliteta hiperparametara u toj iteraciji\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kreiramo navu Optuna studiju koja predstavlja eksperiment u kojem Optuna traži najbolju kombinaciju hiperparametara.\n",
    " - **maximize** opcija govori Optuni da maksimizira neku metriku, u našem slučaju tačnost.\n",
    " - Zatim se pokreće proces optimizacije gdje funkciji šaljemo **objective** funkciju koju smo ranije definisali i ona govori kako da se model ternira i evaluira \n",
    "  - i **n_trials** govori koliko pokušaja optimizacije da se izvrši, naravno bolje je staviti više pokušaja, ali zbog vremenske složenosti ja sam odabrala 5 za početak, što se nije ispostavilo kao loše jer je i dalje tačnost dosta visoka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-23 21:03:29,669] A new study created in memory with name: no-name-0c7182dd-982a-45b1-b2ac-dbbbcef9af65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pokretanje Optuna studije...\n",
      "Pokretanje novog triala ...\n",
      "Treniranje modela sa parametrima: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 37, 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.022572101504552654, 'num_leaves': 109, 'feature_fraction': 0.8271740338049249, 'bagging_freq': 4, 'min_child_samples': 39}\n",
      "Predviđanje na validacionom skupu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-23 22:33:57,343] Trial 0 finished with value: 0.8198549173252715 and parameters: {'learning_rate': 0.022572101504552654, 'num_leaves': 109, 'feature_fraction': 0.8271740338049249, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 0 with value: 0.8198549173252715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 završen za 5427.65 sekundi s preciznošću: 0.8199\n",
      "Pokretanje novog triala ...\n",
      "Treniranje modela sa parametrima: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 37, 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.060323122675371856, 'num_leaves': 75, 'feature_fraction': 0.9461263471443339, 'bagging_freq': 7, 'min_child_samples': 45}\n",
      "Predviđanje na validacionom skupu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-23 23:47:53,996] Trial 1 finished with value: 0.7700943690373268 and parameters: {'learning_rate': 0.060323122675371856, 'num_leaves': 75, 'feature_fraction': 0.9461263471443339, 'bagging_freq': 7, 'min_child_samples': 45}. Best is trial 0 with value: 0.8198549173252715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 završen za 4436.64 sekundi s preciznošću: 0.7701\n",
      "Pokretanje novog triala ...\n",
      "Treniranje modela sa parametrima: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 37, 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.07710187868749381, 'num_leaves': 103, 'feature_fraction': 0.6018646337299879, 'bagging_freq': 5, 'min_child_samples': 84}\n",
      "Predviđanje na validacionom skupu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-24 01:17:32,034] Trial 2 finished with value: 0.7419396895186965 and parameters: {'learning_rate': 0.07710187868749381, 'num_leaves': 103, 'feature_fraction': 0.6018646337299879, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 0 with value: 0.8198549173252715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 završen za 5378.02 sekundi s preciznošću: 0.7419\n",
      "Pokretanje novog triala ...\n",
      "Treniranje modela sa parametrima: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 37, 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.04033652751323631, 'num_leaves': 84, 'feature_fraction': 0.8604216815765149, 'bagging_freq': 3, 'min_child_samples': 9}\n",
      "Predviđanje na validacionom skupu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-24 03:40:55,891] Trial 3 finished with value: 0.7875761711229381 and parameters: {'learning_rate': 0.04033652751323631, 'num_leaves': 84, 'feature_fraction': 0.8604216815765149, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 0 with value: 0.8198549173252715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 završen za 8603.82 sekundi s preciznošću: 0.7876\n",
      "Pokretanje novog triala ...\n",
      "Treniranje modela sa parametrima: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 37, 'verbosity': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.01469002324876744, 'num_leaves': 127, 'feature_fraction': 0.8663276870770615, 'bagging_freq': 7, 'min_child_samples': 29}\n",
      "Predviđanje na validacionom skupu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-24 05:34:16,723] Trial 4 finished with value: 0.8106175677993451 and parameters: {'learning_rate': 0.01469002324876744, 'num_leaves': 127, 'feature_fraction': 0.8663276870770615, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 0 with value: 0.8198549173252715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 završen za 6800.81 sekundi s preciznošću: 0.8106\n",
      "Broj završenih trial-a: 5\n",
      "Najbolji trial:\n",
      "  Vrijednost: 0.8198549173252715\n",
      "  Parametri: \n",
      "    learning_rate: 0.022572101504552654\n",
      "    num_leaves: 109\n",
      "    feature_fraction: 0.8271740338049249\n",
      "    bagging_freq: 4\n",
      "    min_child_samples: 39\n"
     ]
    }
   ],
   "source": [
    "# Optuna za hiperparametarsku pretragu\n",
    "print(\"Pokretanje Optuna studije...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Broj završenih trial-a: {}\".format(len(study.trials)))\n",
    "print(\"Najbolji trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Vrijednost: {}\".format(trial.value))\n",
    "print(\"  Parametri: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treniranje konačnog modela sa najboljim parametrima...\n",
      "Evaluacija na testnom skupu...\n",
      "Tačnost na testnom skupu: 0.8272627068778333\n",
      "Preciznost na testnom skupu: 0.8194036966397518\n",
      "Preciznost na testnom skupu: 0.8272627068778333\n"
     ]
    }
   ],
   "source": [
    "# Treniranje konacnog modela sa najboljim hiperparametrima\n",
    "print(\"Treniranje konačnog modela sa najboljim parametrima...\")\n",
    "best_params = study.best_params\n",
    "final_model = lgb.LGBMClassifier(**best_params, objective='multiclass')\n",
    "\n",
    "# Fitovanje modela na cijelom trening skupu\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluacija na testnom skupu\n",
    "print(\"Evaluacija na testnom skupu...\")\n",
    "y_pred = final_model.predict(X_test)\n",
    "test_precision = precision_score(y_test, y_pred,average='weighted')\n",
    "test_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Tačnost na testnom skupu: {test_accuracy}\")\n",
    "print(f\"Preciznost na testnom skupu: {test_precision}\")\n",
    "print(f\"Preciznost na testnom skupu: {test_recall}\") #Ovde je greska treba pisati odziv ne preciznost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napomenta: greška u kucanju zadnji print je odziv ne preciznost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POREDJENJE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performanse neuronske mreže i LightGBM-a možemo porediti po sve tri metrike: tačnost, preciznost i odziv. Iako su rezultati približni, neuronska mmreža je malo bolja u odnosu na LightGBM. A i u pogledu brzine izvršavanja pokazala se kao bolji model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
